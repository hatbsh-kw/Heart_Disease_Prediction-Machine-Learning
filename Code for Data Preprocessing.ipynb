{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column before encoding:\n",
      "Heart Disease\n",
      "Absence     150\n",
      "Presence    120\n",
      "Name: count, dtype: int64\n",
      "Target column after encoding:\n",
      "Heart Disease\n",
      "0    150\n",
      "1    120\n",
      "Name: count, dtype: int64\n",
      "Target distribution before resampling:\n",
      "Heart Disease\n",
      "0    150\n",
      "1    120\n",
      "Name: count, dtype: int64\n",
      "Prediction probabilities (first 5):\n",
      "[[0.35267537 0.64732463]\n",
      " [0.46754257 0.53245743]\n",
      " [0.94606448 0.05393552]\n",
      " [0.92191865 0.07808135]\n",
      " [0.75578131 0.24421869]]\n",
      "Train Set Accuracy:\n",
      "0.8425925925925926\n",
      "Test Set Accuracy:\n",
      "0.9074074074074074\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        33\n",
      "           1       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.92      0.89      0.90        54\n",
      "weighted avg       0.91      0.91      0.91        54\n",
      "\n",
      "Model Accuracy: 0.9074\n",
      "Confusion Matrix:\n",
      "[[32  1]\n",
      " [ 4 17]]\n",
      "Preprocessed data saved as 'Heart_Disease_Prediction_Cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Heart_Disease_Prediction.csv')\n",
    "\n",
    "# --- Verify target column before encoding ---\n",
    "print(\"Target column before encoding:\")\n",
    "print(df['Heart Disease'].value_counts())\n",
    "\n",
    "# Correctly map target variable 'Presence' -> 1 and 'Absence' -> 0\n",
    "df['Heart Disease'] = df['Heart Disease'].map({'Presence': 1, 'Absence': 0})\n",
    "\n",
    "# Verify target column after encoding\n",
    "print(\"Target column after encoding:\")\n",
    "print(df['Heart Disease'].value_counts())\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "# Handling missing values, outliers, encoding features, and scaling\n",
    "# Your preprocessing steps should go here...\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop(columns=['Heart Disease'])\n",
    "y = df['Heart Disease']\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model Training (using SVM and hyperparameter tuning)\n",
    "svm = SVC(probability=True, class_weight='balanced')\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "# Check target distribution before and after resampling (if resampling is applied)\n",
    "print(\"Target distribution before resampling:\")\n",
    "print(y.value_counts())  # Print the original distribution\n",
    "\n",
    "# Check prediction probabilities before evaluating\n",
    "y_pred_prob = best_model.predict_proba(X_test_scaled)\n",
    "print(\"Prediction probabilities (first 5):\")\n",
    "print(y_pred_prob[:5])  # First 5 prediction probabilities for the test set\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = best_model.predict(X_train_scaled)\n",
    "print(\"Train Set Accuracy:\")\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "print(\"Test Set Accuracy:\")\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Check classification report for the test set\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Final model evaluation\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# --- Save Preprocessed Data ---\n",
    "# Save the cleaned dataset (if needed for future use)\n",
    "df.to_csv('Heart_Disease_Prediction_Cleaned.csv', index=False)\n",
    "print(\"Preprocessed data saved as 'Heart_Disease_Prediction_Cleaned.csv'.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
